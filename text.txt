Diapositiva 1: Título

Título: Memoria Virtual: Desacoplando la Lógica de lo Físico

Subtítulo: Una visión integral de su implementación, rendimiento y gestión.

Presentado por: [Tu Nombre/Grupo]

Fecha: [Fecha]

(Opcional: Logo de la institución/curso)

Diapositiva 2: Agenda / Contenido

Título: Agenda

Repaso de los temas que se cubrirán:

Introducción: ¿Qué es y por qué es necesaria la Memoria Virtual?

Implementación: ¿Cómo funciona técnicamente? (Paginación, Tablas de Páginas, Page Faults)

Estudio de Performance: ¿Cómo medimos y qué afecta su rendimiento? (EAT, Thrashing)

Algoritmos de Reemplazo: ¿Cómo decidir qué página sacar de memoria? (FIFO, LRU, Clock, etc.)

Estrategia de Asignación de Marcos: ¿Cuánta memoria física dar a cada proceso?

Conclusiones

Preguntas y Respuestas

Sección 1: Introducción

Diapositiva 3: El Problema: Limitaciones de la Memoria Física (RAM)

Título: El Mundo Antes de la Memoria Virtual

Puntos Clave:

La memoria RAM es finita y costosa.

Los programas (procesos) necesitan cargarse en RAM para ejecutarse.

¿Qué pasa si un programa es más grande que la RAM disponible?

¿Cómo ejecutar múltiples programas simultáneamente de forma segura y eficiente? (Multiprogramación)

Necesidad de aislar los espacios de memoria de los procesos (Protección).

Complejidad para el programador al gestionar direcciones físicas directamente.

Diapositiva 4: La Solución: Memoria Virtual

Título: ¿Qué es la Memoria Virtual?

Definición: Una técnica de gestión de memoria implementada por el Sistema Operativo (con ayuda del hardware - MMU) que crea una ilusión para los procesos:

Cada proceso "cree" tener su propio espacio de direcciones contiguo y grande (Espacio de Direcciones Lógicas o Virtuales).

Este espacio lógico se desacopla del espacio físico real (RAM).

Permite que un proceso sea más grande que la memoria física disponible.

Facilita la compartición de memoria y la protección entre procesos.

(Diagrama simple: Proceso -> Espacio Lógico vs. RAM -> Espacio Físico)

Diapositiva 5: Beneficios Clave

Título: Ventajas de la Memoria Virtual

Puntos Clave:

Ejecución de programas grandes: Solo las partes necesarias del programa residen en RAM.

Mayor grado de multiprogramación: Más procesos pueden mantenerse en memoria (aunque parcialmente).

Aislamiento y Protección: Cada proceso tiene su espacio virtual, evitando interferencias.

Simplificación para el programador: No necesita preocuparse por la ubicación física real.

Compartición eficiente de memoria: Librerías o código común pueden mapearse en varios espacios virtuales apuntando a la misma memoria física.

Sección 2: Implementación

Diapositiva 6: Conceptos Fundamentales: Paginación

Título: Implementación: Paginación (La técnica más común)

Idea Central:

Espacio de Direcciones Lógicas (Virtuales): Se divide en bloques de tamaño fijo llamados Páginas (Pages).

Memoria Física (RAM): Se divide en bloques del mismo tamaño llamados Marcos (Frames).

El Sistema Operativo mantiene una estructura de datos para traducir direcciones de páginas virtuales a marcos físicos: la Tabla de Páginas (Page Table).

(Diagrama: Espacio Lógico dividido en páginas, RAM dividida en marcos)

Diapositiva 7: Tabla de Páginas (Page Table)

Título: El Mapa: La Tabla de Páginas

Estructura: Típicamente un array (o estructura más compleja como multinivel).

Contenido: Cada entrada (Page Table Entry - PTE) contiene:

Número de Marco (Frame Number): La ubicación física en RAM si la página está cargada.

Bit de Validez/Presencia (Valid/Present Bit): Indica si la página está actualmente en RAM (válido=1) o solo en disco (inválido=0).

Bits de Protección: Permisos (Lectura, Escritura, Ejecución).

Bit de Modificación (Dirty Bit): Indica si la página ha sido modificada desde que se cargó (importante para escribirla de vuelta a disco).

Bit de Referencia (Reference Bit): Indica si la página ha sido accedida recientemente (usado por algoritmos de reemplazo).

(Otros bits específicos de la arquitectura)

(Diagrama: Dirección Lógica -> (Número de Página, Desplazamiento) -> Índice en Tabla de Páginas -> PTE -> Número de Marco -> (Número de Marco, Desplazamiento) -> Dirección Física)

Diapositiva 8: Traducción de Direcciones y MMU

Título: El Traductor: La MMU (Memory Management Unit)

Proceso:

La CPU genera una dirección lógica (virtual).

La MMU (hardware) extrae el número de página.

La MMU consulta la Tabla de Páginas (a menudo usando una caché rápida llamada TLB - Translation Lookaside Buffer).

Si la entrada es válida (está en RAM y en TLB/Tabla): Obtiene el número de marco, lo combina con el desplazamiento y accede a la dirección física en RAM.

Si la entrada es inválida (no en RAM): Se produce un Page Fault.

(Diagrama detallado del proceso de traducción con MMU y TLB)

Diapositiva 9: Page Faults (Fallo de Página)

Título: ¿Qué Pasa Cuando Falta una Página? (Page Fault)

Evento: Ocurre cuando la MMU detecta que el bit de validez de la PTE es 0 (la página no está en RAM).

Secuencia (simplificada):

La MMU genera una interrupción (trap) al Sistema Operativo.

El SO guarda el estado del proceso interrumpido.

El SO verifica si el acceso es válido (permisos, dirección dentro del espacio lógico). Si no, termina el proceso.

El SO localiza la página requerida en el disco (área de swapping/backing store).

El SO busca un marco libre en RAM.

Si no hay marcos libres, ejecuta un algoritmo de reemplazo para seleccionar una página "víctima" en RAM.

Si la página víctima está "sucia" (dirty bit=1), la escribe de vuelta al disco.

El SO carga la página requerida desde el disco al marco liberado/encontrado.

El SO actualiza la Tabla de Páginas (PTE) de la nueva página (bit de validez=1, número de marco) y de la víctima (si hubo, bit de validez=0).

El SO restaura el estado del proceso y reinicia la instrucción que causó el fallo.

Concepto Clave: Demand Paging (Paginación bajo demanda) - Las páginas solo se cargan cuando se necesitan (causan un page fault).

Sección 3: Estudio de Performance

Diapositiva 10: Midiendo el Rendimiento

Título: ¿Cuán Rápida es la Memoria Virtual?

Métrica Principal: Tiempo de Acceso Efectivo (Effective Access Time - EAT)

EAT = (Probabilidad de Hit * Tiempo_acceso_RAM) + (Probabilidad de Miss * Tiempo_servicio_PageFault)

Probabilidad de Miss = Tasa de Fallos de Página (Page Fault Rate - p)

Probabilidad de Hit = 1 - p

Tiempo_servicio_PageFault: Es muy alto (milisegundos) comparado con el acceso a RAM (nanosegundos) porque involucra acceso a disco.

Objetivo: Minimizar la tasa de fallos de página (p). Un p alto degrada drásticamente el rendimiento.

Diapositiva 11: Factores que Afectan el Rendimiento

Título: ¿Qué Impacta el EAT?

Factores:

Tasa de Fallos de Página (p): El factor más crítico. Depende de:

Algoritmo de reemplazo utilizado.

Cantidad de memoria física (marcos) asignada al proceso.

Patrón de acceso a memoria del programa (Localidad de referencia: temporal y espacial).

Velocidad del disco: Determina el tiempo de servicio del page fault.

Eficiencia del TLB (TLB Hit Rate): Reduce la necesidad de consultar la tabla de páginas principal.

Overhead del Sistema Operativo: Tiempo para manejar la interrupción, buscar página, actualizar tablas.

Diapositiva 12: Thrashing (Hiperpaginación)

Título: El Colapso: Thrashing

Definición: Un estado en el que el sistema pasa la mayor parte del tiempo paginando (moviendo páginas entre RAM y disco) en lugar de ejecutar trabajo útil. La CPU está infrautilizada, pero el disco está constantemente ocupado.

Causas Comunes:

Demasiados procesos compitiendo por muy pocos marcos físicos (alto grado de multiprogramación sin suficiente RAM).

Mala estrategia de asignación de marcos.

Procesos con pobre localidad de referencia.

Consecuencia: Rendimiento del sistema se desploma.

Detección/Mitigación: Monitorizar tasa de page faults y uso de CPU, reducir el grado de multiprogramación (suspender procesos), añadir más RAM, usar mejores algoritmos/estrategias de asignación.

Sección 4: Algoritmos de Reemplazo

Diapositiva 13: El Dilema del Reemplazo

Título: ¿A Quién Sacrificamos? Algoritmos de Reemplazo

Problema: Ocurre durante un page fault cuando no hay marcos libres en RAM. Necesitamos elegir una página residente para enviarla al disco ("víctima") y liberar su marco.

Objetivo: Elegir la víctima de forma que se minimice la probabilidad de necesitarla de nuevo en el futuro cercano (minimizar futuros page faults).

Diapositiva 14: Algoritmo Óptimo (OPT / MIN)

Título: El Ideal Inalcanzable: OPT / MIN

Estrategia: Reemplaza la página que no será utilizada por el período más largo en el futuro.

Ventaja: Garantiza la menor tasa posible de page faults.

Desventaja: Imposible de implementar en la práctica, ya que requiere conocer las referencias futuras a memoria.

Utilidad: Sirve como benchmark para comparar otros algoritmos.

Diapositiva 15: Algoritmo FIFO (First-In, First-Out)

Título: Simple pero Injusto: FIFO

Estrategia: Reemplaza la página que lleva más tiempo en memoria (la que llegó primero). Se gestiona con una cola simple.

Ventaja: Muy fácil de implementar.

Desventaja: Puede reemplazar páginas muy utilizadas simplemente porque llevan mucho tiempo. Sufre de la Anomalía de Belady: añadir más marcos puede incrementar la tasa de page faults (contraintuitivo).

Diapositiva 16: Algoritmo LRU (Least Recently Used)

Título: Mirando al Pasado Reciente: LRU

Estrategia: Reemplaza la página que no ha sido utilizada por el período más largo en el pasado. Se basa en la localidad temporal (si no se usó recientemente, probablemente no se use pronto).

Ventaja: Buena aproximación a OPT, no sufre la Anomalía de Belady, buen rendimiento general.

Desventaja: Difícil y costoso de implementar perfectamente. Requiere hardware especial (contadores o una pila actualizada en cada referencia a memoria).

Diapositiva 17: Algoritmos de Aproximación a LRU

Título: Soluciones Prácticas: Aproximaciones a LRU

Motivación: LRU es bueno pero caro. Se buscan algoritmos que se aproximen a su comportamiento con menos overhead. Usan el Bit de Referencia (hardware lo pone a 1 cuando se accede a la página, el SO lo resetea periódicamente).

Ejemplos:

Algoritmo del Reloj (Clock / Second-Chance): Organiza las páginas en un buffer circular (como un reloj). Cuando busca víctima, mira el bit de referencia:

Si es 0: Elige esta página como víctima.

Si es 1: Le da una "segunda oportunidad", pone el bit a 0 y avanza el puntero del reloj.

Enhanced Second-Chance / NRU (Not Recently Used): Considera dos bits: Referencia (R) y Modificación (M). Clasifica páginas en 4 categorías (prioridad de reemplazo de menor a mayor): (0,0), (0,1), (1,0), (1,1). Reemplaza la mejor candidata de la categoría más baja no vacía.

Ventajas: Implementación más factible, buen rendimiento (mejor que FIFO, cercano a LRU en muchos casos).

Diapositiva 18: Otros Algoritmos (Mención)

Título: Otras Estrategias (Breve Mención)

LFU (Least Frequently Used): Reemplaza la página usada menos veces. Requiere contadores. Puede mantener páginas antiguas poco usadas.

MFU (Most Frequently Used): Reemplaza la página usada más veces (idea: tiene baja probabilidad de necesitarse pronto). Contraintuitivo.

Algoritmos basados en Conjunto de Trabajo (Working Set): Intentan mantener en memoria el conjunto de páginas activamente usadas por un proceso.

Sección 5: Estrategia de Asignación de Marcos (Frames)

Diapositiva 19: Repartiendo la Torta: Asignación de Marcos

Título: ¿Cuánta RAM para Cada Proceso?

Problema: ¿Cómo distribuir los marcos de memoria física disponibles entre los múltiples procesos que compiten por ellos?

Consideraciones:

Mínimo de Marcos: Cada proceso necesita un número mínimo de marcos para ejecutarse eficientemente (depende de la arquitectura y la necesidad de albergar instrucciones que acceden a múltiples páginas). Si tiene menos, la tasa de page faults se dispara.

Impacto en el Rendimiento: Pocos marcos -> Alta tasa de page faults. Demasiados marcos -> Menos procesos pueden ejecutarse simultáneamente.

Diapositiva 20: Estrategias de Asignación Fija

Título: Asignación Fija

La cantidad de marcos asignada a un proceso no cambia durante su ejecución.

Tipos:

Asignación Igualitaria (Equal Allocation): Si hay m marcos y n procesos, cada proceso recibe m/n marcos. Simple pero ignora las necesidades reales de cada proceso.

Asignación Proporcional (Proportional Allocation): Asigna marcos en proporción al tamaño (o prioridad) del proceso. Procesos más grandes/importantes obtienen más marcos. Más justo que la igualitaria.

Diapositiva 21: Estrategias de Asignación Dinámica / Prioritaria

Título: Asignación Dinámica y Prioritaria

La cantidad de marcos puede variar durante la ejecución, usualmente basada en la tasa de page faults del proceso.

Idea: Si un proceso tiene muchos page faults, quizás necesite más marcos. Si tiene pocos, quizás se le puedan quitar algunos para dárselos a otros.

Ejemplo: Usar la tasa de page faults para ajustar la asignación (PFF - Page Fault Frequency).

Prioridad: Procesos de alta prioridad pueden recibir más marcos o tener preferencia.

Diapositiva 22: Alcance del Reemplazo: Local vs. Global

Título: ¿Dónde Buscar la Víctima? Local vs. Global

Cuando un proceso necesita un marco y no hay libres, ¿de dónde elige la víctima el algoritmo de reemplazo?

Reemplazo Local (Local Replacement):

El proceso solo puede elegir una víctima de entre sus propios marcos asignados.

Ventaja: El rendimiento de un proceso es menos afectado por el comportamiento de otros.

Desventaja: Un proceso puede sufrir muchos page faults aunque haya marcos infrautilizados en otros procesos.

Reemplazo Global (Global Replacement):

El proceso puede elegir una víctima de cualquier marco en memoria, incluso los asignados a otros procesos (generalmente, se eligen víctimas de procesos de menor prioridad).

Ventaja: Más flexible, puede mejorar el rendimiento general del sistema al dar marcos a quien más los necesita dinámicamente. Mayor rendimiento/throughput.

Desventaja: El comportamiento de un proceso es menos predecible, puede ser afectado por otros. Más complejo de gestionar.

(La mayoría de los sistemas operativos modernos usan alguna forma de reemplazo global).

Sección 6: Conclusiones

Diapositiva 23: Resumen y Conclusiones

Título: En Resumen

Puntos Clave:

La Memoria Virtual es una abstracción esencial en los SO modernos.

Desacopla el espacio lógico del físico usando Paginación y Tablas de Página.

Los Page Faults son costosos pero necesarios para cargar páginas bajo demanda.

El rendimiento (EAT) depende críticamente de minimizar la tasa de page faults.

Los Algoritmos de Reemplazo (LRU y sus aproximaciones como Clock) son cruciales cuando la memoria está llena.

Las Estrategias de Asignación (Fija/Dinámica) y el Alcance del Reemplazo (Local/Global) determinan cómo se comparten los recursos físicos.

Un mal manejo puede llevar al Thrashing.

Diapositiva 24: Importancia Final

Título: ¿Por Qué Es Tan Importante?

La Memoria Virtual permite:

Sistemas Multitarea eficientes y seguros.

Ejecución de aplicaciones complejas y grandes.

Mejor utilización de la costosa memoria RAM.

Una base fundamental para muchas otras características del SO (memoria compartida, copy-on-write, etc.).

Sección 7: Preguntas

Diapositiva 25: Preguntas y Respuestas

Título: ¿Preguntas?

(Espacio para abrir la discusión)

(Opcional: Información de contacto/referencias)

Notas Adicionales para el Presentador:

Diagramas: Son esenciales para explicar la paginación, traducción de direcciones y page faults. Prepáralos bien.

Analogías: Pueden ayudar a entender conceptos abstractos (ej. libro con índice como tabla de páginas, escritorio pequeño con archivador como RAM/Disco).

Ejemplos Numéricos: Para EAT o para mostrar cómo funcionan los algoritmos de reemplazo con una cadena de referencias.

Ritmo: Ajusta la profundidad de cada tema según el tiempo disponible y el nivel de la audiencia.
